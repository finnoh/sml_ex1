---
title: "SML: Exercise 2"
author: "Finn-Ole HÃ¶ner, Thao Le, Jason Wang, Ramon Snellen"
date: "`r Sys.Date()`"
output: pdf_document
ulrcolor: CornflowerBlue
header-includes:
  - \usepackage{float}
  - \usepackage{booktabs}
  - \usepackage{fancyvrb}
  - \usepackage{float}
  - \newcommand{\mat}[1]{\mathbf{#1}}
  - \newcommand{\vect}[1]{\boldsymbol{#1}}
bibliography: citations.bib
pdf-engine: xelatex
cap-location: top
toc: false
toc-title: Contents
number-sections: true
mainfont: Helvetica
setspace:
  linestretch: 1.25
fig-align: center
table-align: center
fig-pos: H
table-pos: H
execute:
  echo: true
  warning: false
  eval: true
code-line-numbers: false
colorlinks: true
code-block-bg: darkgray
df-print: default
highlight-style: arrow-dark
biblio-title: References
---

\section{Introduction}

This report aims to find the best set of predictors for past cumulative grocery sales (in dollars) for Dominick's Finer Foods.

\section{Data}

The data set contains seven years of store-level data collected at Dominick's Finer Foods by the University of Chicago Booth School of Business. The data can be found at \url{https://www.chicagobooth.edu/research/kilts/datasets/dominicks}. The data set contains 50 variables, which stem from:

```{=tex}
\begin{enumerate}
\item customer count files, which contain information about in-store traffic;
\item a demographics file, which contains store-specific demographic data;
\item number identification files, which contain product information.
\end{enumerate}
```
Of the fifty variables, \verb+GROCERY_sum+ is used as dependent variable. Furthermore, four categorical variables are dropped; \verb+STORE+, \verb+CITY+, \verb+ZIP+ and \verb+SPHINDX+. The remaining variables are potential predictor variables.

\section{Method}

To find the optimal set of predictor variables, and there corresponding weights, we use a regression method that penalizes the size of coefficients. The penalty is useful when predictors are collinear, or the number of predictors destabilizes estimation. This data set only consists of 77 observations for 50 variables, hence the number of predictors would destabilize estimation if not penalized.

Let $P(\beta)$ denote a general penalty function. Then, the penalized regression equation becomes 
$$
L(\beta) = (\mathbf{y}-\mathbf{x}\beta)^{T}(\mathbf{y}-\mathbf{x}\beta) + \lambda P(\beta),
$$ 
where $\lambda$ is the hyperparameter that determines the strength of the penalty. When $P(\beta) = \beta^{2}$, the regression is called 'ridge' regression. Similarly, when $P(\beta) = |\beta|$, the regression is called 'LASSO' regression. Finally, any convex combination $P(\beta) = \alpha |\beta| + (1-\alpha) \beta^{2}$ of the 'ridge' and 'LASSO' penalty, where $\alpha$ denotes the weight on the 'LASSO' penalty, is called 'elastic net'.

\section{Results}

\section{Conclusion and Discussion}

\section{Code}

# References

